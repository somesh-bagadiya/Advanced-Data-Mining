# -*- coding: utf-8 -*-
"""ADM-Collaborative Filtering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UmVMQoDCzktypaYCI1teCtkFaGQ_Defh
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
ratings_df = pd.read_csv("/content/drive/MyDrive/Data/ml-25m/ratings.csv")

ratings_df.head()

ratings_df = ratings_df.drop(columns=["timestamp"])

ratings_df.shape

ratings_df = ratings_df.dropna()

ratings_df = ratings_df.drop_duplicates()

ratings_df.shape

missing_values = ratings_df.isnull().sum()
print("Missing values:")
print(missing_values)

uniq_users = pd.unique(ratings_df["userId"])
len(uniq_users)

movie_users = pd.unique(ratings_df["movieId"])
len(movie_users)

uniq_ratings = pd.unique(ratings_df["rating"])
len(uniq_ratings), uniq_ratings

from sklearn.model_selection import train_test_split

training_data = []
validation_data = []
testing_data = []

grouped_ratings = ratings_df.groupby('userId')

for _, group in grouped_ratings:
    train, test = train_test_split(group, test_size=0.1, random_state=42)
    training_data.append(train)
    testing_data.append(test)

training_df = pd.concat(training_data)
testing_df = pd.concat(testing_data)

training_df.to_csv("/content/drive/MyDrive/Data/ml-25m/training.csv", index=False)
testing_df.to_csv("/content/drive/MyDrive/Data/ml-25m/testing.csv", index=False)

!pip install pyspark

from pyspark.sql import SparkSession
from pyspark.ml.recommendation import ALS
from pyspark.ml.evaluation import RegressionEvaluator

spark = SparkSession.builder.appName("Collaborative Filtering Example").getOrCreate()
training_data = spark.read.csv("/content/drive/MyDrive/Data/ml-25m/training.csv", header=True, inferSchema=True)

als = ALS(rank=25, maxIter=10, regParam=0.01, userCol="userId", itemCol="movieId", ratingCol="rating",
          coldStartStrategy="drop", nonnegative=True, seed=16)

model = als.fit(training_data)

testing_data = spark.read.csv("/content/drive/MyDrive/Data/ml-25m/testing.csv", header=True, inferSchema=True)
predictions = model.transform(testing_data)
evaluator = RegressionEvaluator(metricName="rmse", labelCol="rating", predictionCol="prediction")
rmse = evaluator.evaluate(predictions)

print("Root Mean Squared Error (RMSE) on validation data = " + str(rmse))

spark.stop()

